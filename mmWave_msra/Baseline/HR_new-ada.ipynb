{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "import os\r\n",
    "import pickle\r\n",
    "import numpy as np\r\n",
    "import matplotlib as mpl\r\n",
    "\r\n",
    "from easydict import EasyDict\r\n",
    "import pandas as pd\r\n",
    "import torch\r\n",
    "import torch.nn as nn\r\n",
    "import torch.optim as optim\r\n",
    "import torch.nn.functional as F\r\n",
    "from torch.autograd import Variable\r\n",
    "import torch.utils.data as Data\r\n",
    "from scipy.io import loadmat\r\n",
    "import scipy.io as sio"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "# parameter\r\n",
    "batch_size = 8\r\n",
    "opts = EasyDict()\r\n",
    "opts.input_size = 2\r\n",
    "opts.output_size = 1\r\n",
    "opts.hidden_size = 128\r\n",
    "opts.num_layers = 2\r\n",
    "opts.nums_epoch = 200\r\n",
    "opts.dropout = 0.5 \r\n",
    "opts.isBidirectional = True;\r\n",
    "opts.layer_size = 2\r\n",
    "opts.sequence_length = 300\r\n",
    "opts.attention_size = 10\r\n",
    "opts.adaTrain = 1\r\n",
    "opts.nums_ada_epoch = 5\r\n",
    "device = torch.device(\"cuda:2\" if torch.cuda.is_available() else \"cpu\")\r\n",
    "\r\n",
    "name_labels = [\"p1\",\"p2\" ]\r\n",
    "# ,\"noise\",\"differentplace\"  \"tabish\" \"john\"\r\n",
    "def ZscoreNormalization(x):\r\n",
    "    \"\"\"Z-score normaliaztion\"\"\"\r\n",
    "    std = np.std(x)\r\n",
    "    mean = np.mean(x)\r\n",
    "    x = (x - np.mean(x)) / np.std(x)\r\n",
    "    return x,mean,std\r\n",
    "file_power_name = []\r\n",
    "file_HR_name = []\r\n",
    "for i in range(1,11):\r\n",
    "    name = 'radar_'+ str(i).rjust(2,'0') + '.csv'\r\n",
    "    file_power_name.append(name)\r\n",
    "print(file_power_name)\r\n",
    "for i in range(1,11):\r\n",
    "    name = 'HR'+ str(i).rjust(2,'0') + '.npy'\r\n",
    "    file_HR_name.append(name)   \r\n",
    "print(file_HR_name)\r\n",
    "\r\n",
    "para_normal_sep = 6\r\n",
    "para_normal_jian = 15"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['radar_01.csv', 'radar_02.csv', 'radar_03.csv', 'radar_04.csv', 'radar_05.csv', 'radar_06.csv', 'radar_07.csv', 'radar_08.csv', 'radar_09.csv', 'radar_10.csv']\n",
      "['HR01.npy', 'HR02.npy', 'HR03.npy', 'HR04.npy', 'HR05.npy', 'HR06.npy', 'HR07.npy', 'HR08.npy', 'HR09.npy', 'HR10.npy']\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "source": [
    "#-*- coding : utf-8-*-\r\n",
    "\r\n",
    "import os\r\n",
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "from scipy import interpolate\r\n",
    "import random\r\n",
    "\r\n",
    "name_labels = [\"p1\",\"p2\" ]\r\n",
    "file_HR_name = []\r\n",
    "for i in range(1,11):\r\n",
    "    name = 'HR'+ str(i).rjust(2,'0') + '.csv'\r\n",
    "    file_HR_name.append(name)\r\n",
    "\r\n",
    "def readDir(dirPath,pathArray,res,prevPath = \"\"):\r\n",
    "    if dirPath[-1] == '/':\r\n",
    "        return\r\n",
    "    flag = False\r\n",
    "    allFiles = []\r\n",
    "    if os.path.isdir(dirPath):\r\n",
    "        fileList = os.listdir(dirPath)\r\n",
    "        fileList.sort()\r\n",
    "        for f in fileList:\r\n",
    "            if f in file_HR_name:\r\n",
    "                flag = True\r\n",
    "            file_name = f\r\n",
    "            f = dirPath+'/'+f\r\n",
    "            if os.path.isdir(f):\r\n",
    "                subFiles = readDir(f,pathArray,res,dirPath)\r\n",
    "                allFiles = subFiles + allFiles \r\n",
    "            else:\r\n",
    "                if flag:\r\n",
    "#                     print(f)\r\n",
    "#                     print(prevPath)\r\n",
    "                    pathArray.append(f)\r\n",
    "                    csv_data = pd.read_csv(f,engine='python')\r\n",
    "                    header = np.array(csv_data.columns)\r\n",
    "                    \r\n",
    "                    if(header[1] == u'数据组 1:心率(bpm)' and header[2] == u'数据组 1:力(N)'):\r\n",
    "                        data = np.array(csv_data.iloc[0:301])\r\n",
    "                        rr = data[:,3]\r\n",
    "                        res_rr = np.delete(rr,np.where(np.isnan(rr)))\r\n",
    "                        if((res_rr>10).all() == False or (res_rr<30).all() == False):\r\n",
    "                            idx = np.where((res_rr > 10) & (res_rr <30))\r\n",
    "                            idx_abnormal = np.where((res_rr < 10) | (res_rr > 30))\r\n",
    "                            \r\n",
    "                            if len(idx[0]) == 0:\r\n",
    "                                temp = 15 + np.random.randn(4)\r\n",
    "                                res_rr = np.around(temp, decimals=1)\r\n",
    "                            elif len(idx[0]) == 1:\r\n",
    "                                temp = res_rr[idx[0]] + np.random.randn(4)\r\n",
    "                                res_rr = np.around(temp, decimals=1)\r\n",
    "                            else:\r\n",
    "                                z = np.polyfit(idx[0],res_rr[idx],1)\r\n",
    "                                p= np.poly1d(z)\r\n",
    "                                xnew = np.arange(4)\r\n",
    "                                ynew = p(xnew)\r\n",
    "                                ynew_idx = np.where((ynew < 10) | (ynew > 30))\r\n",
    "                                ynew[ynew_idx] = 15 + np.random.randn(len(ynew_idx[0]))\r\n",
    "                                res_rr = np.around(ynew, decimals=1)\r\n",
    "#                             print('Warnning: the rr is less than 5\\n path:'+str(f))\r\n",
    "                        res.append(data)\r\n",
    "                        res_hr = data[:,1]\r\n",
    "                        res_hr = np.delete(res_hr,np.where(np.isnan(res_hr)))\r\n",
    "                        xnew = np.linspace(0,3,num= 301)\r\n",
    "                        fun_hr=interpolate.interp1d(np.linspace(0,3,num= 31),res_hr,kind=\"slinear\")\r\n",
    "                        res_hr = fun_hr(xnew)\r\n",
    "                        \r\n",
    "                        fun=interpolate.interp1d(np.arange(4),res_rr,kind=\"slinear\")\r\n",
    "                        \r\n",
    "                        res_rr=fun(xnew)\r\n",
    "                        res_rr = np.around(res_rr, decimals=1)\r\n",
    "                        path_save_gt = prevPath +\"/vitalSign\"\r\n",
    "                        if not os.path.exists(path_save_gt):\r\n",
    "                            os.makedirs(path_save_gt)\r\n",
    "                        res_gt = np.vstack((res_hr,res_rr))\r\n",
    "                        res_gt = res_gt[:,:-1]\r\n",
    "                        \r\n",
    "                        path_save_gt = path_save_gt+\"/\"+os.path.splitext(file_name)[0]+\".npy\"\r\n",
    "                        np.save(path_save_gt,res_gt.T)\r\n",
    "                        \r\n",
    "        \r\n",
    "                    else:\r\n",
    "                        print('Failed becaues of index error\\n path:'+str(f))\r\n",
    "                    allFiles.append(f)\r\n",
    "                    flag = False\r\n",
    "        return allFiles\r\n",
    "\r\n",
    "for name in name_labels:    \r\n",
    "    path_save_dir = \"/home/kaixin/RobustVSDataset/aggregated/\"+name+\"/\"\r\n",
    "    if not os.path.exists(path_save_dir):\r\n",
    "        os.makedirs(path_save_dir) \r\n",
    "    path = \"/data2/jian/RobustVSDataset/\"+name\r\n",
    "    \r\n",
    "#     path_save = path_save_dir +'dir.txt'\r\n",
    "#     path_save_hr = path_save_dir + 'hr.npy'\r\n",
    "#     path_save_power = path_save_dir + 'rr_power.npy'\r\n",
    "#     path_save_rr = path_save_dir + 'rr.npy'\r\n",
    "    \r\n",
    "    pathArray =  []\r\n",
    "    resArray = []\r\n",
    "    res = readDir(path,pathArray,resArray)\r\n",
    "    resArray = np.array(resArray)\r\n",
    "\r\n",
    "#     np.savetxt(path_save,np.array(pathArray),fmt='%s')\r\n",
    "#     res_hr = resArray[:,:,1]\r\n",
    "#     res_rr = resArray[:,:,3]\r\n",
    "#     # res_hr = resArray[(~np.isnan())]\r\n",
    "#     #  = \r\n",
    "#     # resArray[:,:,3]\r\n",
    "#     res_hr = np.delete(res_hr,np.where(np.isnan(res_hr))[1],axis=1)\r\n",
    "#     res_power = resArray[:,:,2];\r\n",
    "#     res_rr = np.delete(res_rr,np.where(np.isnan(res_rr))[1],axis=1)\r\n",
    "# #     print(res_hr.shape)\r\n",
    "# #     print(res_power.shape)\r\n",
    "# #     print(res_rr.shape)\r\n",
    "#     np.save(path_save_hr,res_hr)\r\n",
    "#     np.save(path_save_rr,res_rr)\r\n",
    "#     np.save(path_save_power,res_power)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "# LSTM model\r\n",
    "class LSTM(nn.Module):\r\n",
    "    def __init__(self):\r\n",
    "        super(LSTM, self).__init__()\r\n",
    "        self.lstm = torch.nn.LSTM(input_size = opts.input_size,hidden_size = opts.hidden_size, num_layers = opts.num_layers,\r\n",
    "                                  batch_first = True,bidirectional = opts.isBidirectional,dropout = opts.dropout)\r\n",
    "        for name, param in self.lstm.named_parameters():\r\n",
    "#             if 'bias' in name:\r\n",
    "#                 nn.init.constant_(param, 0.0)\r\n",
    "            if 'weight' in name:\r\n",
    "                nn.init.xavier_uniform_(param)\r\n",
    "        self.out = torch.nn.Linear(opts.hidden_size*2, opts.output_size)\r\n",
    "    \r\n",
    "    def forward(self, sequence):\r\n",
    "        r_out,_ = self.lstm(sequence)\r\n",
    "        out = self.out(r_out)\r\n",
    "        return out\r\n",
    "# read power file\r\n",
    "def readPowerDir(dirPath,pathArray,res):\r\n",
    "    if dirPath[-1] == '/':\r\n",
    "        return\r\n",
    "    flag = False\r\n",
    "    allFiles = []\r\n",
    "    if os.path.isdir(dirPath):\r\n",
    "        fileList = os.listdir(dirPath)\r\n",
    "        fileList.sort()\r\n",
    "        for f in fileList:\r\n",
    "            if f in file_power_name:\r\n",
    "                flag = True\r\n",
    "            f = dirPath+'/'+f\r\n",
    "            if os.path.isdir(f):\r\n",
    "                subFiles = readPowerDir(f,pathArray,res)\r\n",
    "                allFiles = subFiles + allFiles \r\n",
    "            else:\r\n",
    "                if flag:\r\n",
    "                    \r\n",
    "                    pathArray.append(f)\r\n",
    "                    csv_data = pd.read_csv(f,engine='python',header=None)\r\n",
    "                    data = np.array(csv_data)\r\n",
    "                    for i in range(data.shape[0]):\r\n",
    "                        data[:,1],_,_ = ZscoreNormalization(data[:,1])\r\n",
    "                        data[:,2],_,_ = ZscoreNormalization(data[:,2])\r\n",
    "                    res.append(data)\r\n",
    "                    allFiles.append(f)\r\n",
    "                    flag = False\r\n",
    "    return allFiles\r\n",
    "\r\n",
    "# read HR file\r\n",
    "def readHRDir(dirPath,pathArray,res):\r\n",
    "    if dirPath[-1] == '/':\r\n",
    "        return\r\n",
    "    flag = False\r\n",
    "    allFiles = []\r\n",
    "    if os.path.isdir(dirPath):\r\n",
    "        fileList = os.listdir(dirPath)\r\n",
    "        fileList.sort()\r\n",
    "        for f in fileList:\r\n",
    "            if f in file_HR_name:\r\n",
    "                flag = True\r\n",
    "            f = dirPath+'/'+f\r\n",
    "            if os.path.isdir(f):\r\n",
    "                subFiles = readHRDir(f,pathArray,res)\r\n",
    "                allFiles = subFiles + allFiles \r\n",
    "            else:\r\n",
    "                if flag:\r\n",
    "                    \r\n",
    "                    pathArray.append(f)\r\n",
    "                    data = np.load(f)\r\n",
    "#                     for i in range(data.shape[0]):\r\n",
    "#                         data[:,1],_,_ = ZscoreNormalization(data[:,1])\r\n",
    "#                         data[:,0],_,_ = ZscoreNormalization(data[:,0])\r\n",
    "                    res.append(data)\r\n",
    "                    allFiles.append(f)\r\n",
    "                    flag = False\r\n",
    "    return allFiles\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "average = []\r\n",
    "average_fix = []\r\n",
    "average_amb = []\r\n",
    "# Cross-validation len(name_labels)\r\n",
    "for i in range(len(name_labels)):\r\n",
    "    name_mask = []\r\n",
    "    name_mask.append(name_labels[i])\r\n",
    "    # read power and distance from file according ro name_labels as trainset\r\n",
    "    PowerTrain = np.array([0])\r\n",
    "    HRTrain = np.array([0])\r\n",
    "    for name in name_labels:\r\n",
    "        if(name in name_mask):\r\n",
    "            continue\r\n",
    "        pathArray =  []\r\n",
    "        power = []\r\n",
    "        HR = []\r\n",
    "        path = \"/data2/jian/RobustVSDataset/\"+name\r\n",
    "        res = readPowerDir(path,pathArray,power)\r\n",
    "        pathArray =  []\r\n",
    "        res = readHRDir(path,pathArray,HR)\r\n",
    "        power = np.array(power)\r\n",
    "        HR = np.array(HR)\r\n",
    "        PowerTrain = power if  PowerTrain.any() == 0 else np.concatenate((PowerTrain, power), axis = 0)\r\n",
    "        HRTrain = HR if  HRTrain.any() == 0 else np.concatenate((HRTrain, HR), axis = 0)\r\n",
    "    # read power and distance from file according ro name_mask as testset\r\n",
    "    PowerTest = np.array([0])\r\n",
    "    HRTest = np.array([0])    \r\n",
    "    for name in name_mask:\r\n",
    "        pathArray =  []\r\n",
    "        power = []\r\n",
    "        HR = []\r\n",
    "        path = \"/data2/jian/RobustVSDataset/\"+ name\r\n",
    "        res = readPowerDir(path,pathArray,power)\r\n",
    "        pathArray =  []\r\n",
    "        res = readHRDir(path,pathArray,HR)\r\n",
    "        power = np.array(power)\r\n",
    "        HR = np.array(HR)\r\n",
    "        PowerTest = power if  PowerTest.any() == 0 else np.concatenate((PowerTest, power), axis = 0)\r\n",
    "        HRTest = HR if  HRTest.any() == 0 else np.concatenate((HRTest, HR), axis = 0)\r\n",
    "#     print(\"Read file success!\")\r\n",
    "    \r\n",
    "    \r\n",
    "    model = LSTM()\r\n",
    "    model.to(device)\r\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.005)   # optimize parameters\r\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.8,weight_decay=1e-4)\r\n",
    "    loss_func = nn.MSELoss()\r\n",
    "\r\n",
    "    inputs, targets = torch.from_numpy(PowerTrain[:,:,1:]).type(torch.FloatTensor),torch.from_numpy(HRTrain[:,:,0]).type(torch.FloatTensor)\r\n",
    "    inputs, targets = inputs.to(device), targets.to(device)\r\n",
    "    torch_dataset = Data.TensorDataset(inputs,targets)\r\n",
    "    loader = Data.DataLoader(\r\n",
    "                    dataset=torch_dataset,      # torch TensorDataset format\r\n",
    "                    batch_size=batch_size,      # mini batch size\r\n",
    "                    shuffle=True,                            \r\n",
    "                )\r\n",
    "    train_loss, train_count, val_loss, val_count = 0,0,0,0\r\n",
    "    val_inputs,val_targets  = torch.from_numpy(PowerTest[:,:,1:]).type(torch.FloatTensor),torch.from_numpy(HRTest[:,:,0]).type(torch.FloatTensor)\r\n",
    "    val_inputs,val_targets = val_inputs.to(device), val_targets.to(device)\r\n",
    "    x_ada = torch.zeros(val_inputs.shape)\r\n",
    "    y_ada = torch.zeros(val_targets.shape)\r\n",
    "    print(x_ada.shape,y_ada.shape,val_inputs.shape)\r\n",
    "    for ii in range(x_ada.shape[0]):\r\n",
    "        for jj in range(50):\r\n",
    "            if(opts.adaTrain > 0):\r\n",
    "                x_ada[ii,200:,:] = val_inputs[ii,200:,:]\r\n",
    "                y_ada[ii,250+jj] = val_targets[ii,-1] \r\n",
    "                y_ada[ii,200+jj] = val_targets[ii,-50] \r\n",
    "#                 y_ada[ii,150+jj] = val_targets[ii,-100]\r\n",
    "#                 y_ada[ii,100+jj] = val_targets[ii,-150]\r\n",
    "    val_inputs = val_inputs.permute(1, 0, 2)\r\n",
    "    val_targets = val_targets.t()\r\n",
    "    val_targets = val_targets[:,:,np.newaxis]\r\n",
    "    \r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "#   begin train\r\n",
    "    for epoch in range(0, opts.nums_epoch+1):\r\n",
    "        for step, (x, y) in enumerate(loader):\r\n",
    "            \r\n",
    "            model.zero_grad()\r\n",
    "            model.train()\r\n",
    "            x = x.permute(1, 0, 2)\r\n",
    "            y = y.t()\r\n",
    "            y = y[:,:,np.newaxis]\r\n",
    "            prediction= model(x)\r\n",
    "            loss = loss_func(prediction, y)\r\n",
    "            optimizer.zero_grad()\r\n",
    "            loss.backward()\r\n",
    "            optimizer.step() \r\n",
    "            train_loss += loss.item()\r\n",
    "            train_count += 1\r\n",
    "\r\n",
    "#         model.eval()\r\n",
    "#         with torch.no_grad():\r\n",
    "#             val_predict = model(val_inputs)\r\n",
    "#             loss_ = loss_func(val_predict, val_targets)\r\n",
    "#             val_loss += loss_.item()\r\n",
    "#             val_count += 1\r\n",
    "#         if(epoch% 50 == 0):\r\n",
    "#             print('Epoch %d / %d     Train loss: %f     val loss: %f'% (epoch,opts.nums_epoch,  train_loss/train_count,val_loss/val_count)) \r\n",
    "    \r\n",
    "    x_ada,y_ada= x_ada.to(device), y_ada.to(device)\r\n",
    "#     print(x_ada)\r\n",
    "#     print(y_ada)\r\n",
    "    torch_dataset_ada = Data.TensorDataset(x_ada,y_ada)\r\n",
    "    \r\n",
    "    loader1 = Data.DataLoader(\r\n",
    "                    dataset=torch_dataset_ada,      # torch TensorDataset format\r\n",
    "                    batch_size=batch_size,      # mini batch size\r\n",
    "                    shuffle=True,                            \r\n",
    "                )\r\n",
    "    for epoch in range(0,opts.nums_ada_epoch+1):\r\n",
    "        for step, (x, y) in enumerate(loader1):\r\n",
    "            model.zero_grad()\r\n",
    "            model.train()\r\n",
    "            x = x.permute(1, 0, 2)\r\n",
    "            y = y.t()\r\n",
    "            y = y[:,:,np.newaxis]\r\n",
    "            \r\n",
    "            prediction= model(x)\r\n",
    "            \r\n",
    "            \r\n",
    "            loss = loss_func(prediction[200:,], y[200:,])\r\n",
    "            optimizer.zero_grad()\r\n",
    "            loss.backward()\r\n",
    "            optimizer.step() \r\n",
    "    \r\n",
    "    model.zero_grad()\r\n",
    "    \r\n",
    "    val_predict = model(val_inputs)\r\n",
    "    sum = 0\r\n",
    "    sum_fix = 0\r\n",
    "    sum_amb = 0\r\n",
    "    for i in range(val_predict.shape[1]):\r\n",
    "        if name_mask[0] == \"jian\":\r\n",
    "            para = para_normal_jian\r\n",
    "        else:\r\n",
    "            para = para_normal_sep\r\n",
    "        if(i < para):\r\n",
    "            sum_amb += torch.sum(torch.abs(val_predict[:,i]-val_targets[:,i]))/300\r\n",
    "        else:\r\n",
    "            sum_fix += torch.sum(torch.abs(val_predict[:,i]-val_targets[:,i]))/300\r\n",
    "        sum += torch.sum(torch.abs(val_predict[:,i]-val_targets[:,i]))/300\r\n",
    "        print('index:%d    MSE: %f '%(i,torch.sum(torch.abs(val_predict[:,i]-val_targets[:,i]))/300))\r\n",
    "    print('Test: %s  average MSE: %f average fix MSE: %f  average amb MSE: %f' % (name_mask[0],sum/val_predict.shape[1],\r\n",
    "                                                                              sum_fix/(val_predict.shape[1]-para),sum_amb/para))\r\n",
    "    average.append((sum/val_predict.shape[1]).item())\r\n",
    "    average_fix.append((sum_fix/(val_predict.shape[1]-para)).item())\r\n",
    "    \r\n",
    "    average_amb.append((sum_amb/(para)).item())\r\n",
    "print(\"average: %f\" %(np.mean(average)))\r\n",
    "print(\"average fix: %f\" %(np.mean(average_fix)))\r\n",
    "print(\"average amb: %f\" %(np.mean(average_amb)))\r\n",
    "print(average)\r\n",
    "\r\n",
    "np.savetxt(\"generation_ada_2point.csv\", average)\r\n",
    "print(average_fix)\r\n",
    "print(average_amb)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([18, 300, 2]) torch.Size([18, 300]) torch.Size([18, 300, 2])\n",
      "index:0    MSE: 2.803355 \n",
      "index:1    MSE: 2.270577 \n",
      "index:2    MSE: 2.301537 \n",
      "index:3    MSE: 1.565176 \n",
      "index:4    MSE: 3.598841 \n",
      "index:5    MSE: 4.066598 \n",
      "index:6    MSE: 6.582900 \n",
      "index:7    MSE: 2.504412 \n",
      "index:8    MSE: 6.811568 \n",
      "index:9    MSE: 4.228043 \n",
      "index:10    MSE: 1.364400 \n",
      "index:11    MSE: 3.417266 \n",
      "index:12    MSE: 3.673333 \n",
      "index:13    MSE: 3.159280 \n",
      "index:14    MSE: 3.194962 \n",
      "index:15    MSE: 4.374754 \n",
      "index:16    MSE: 8.613933 \n",
      "index:17    MSE: 8.084437 \n",
      "Test: kaixin  average MSE: 4.034187 average fix MSE: 4.667441  average amb MSE: 2.767681\n",
      "torch.Size([18, 300, 2]) torch.Size([18, 300]) torch.Size([18, 300, 2])\n",
      "index:0    MSE: 9.238263 \n",
      "index:1    MSE: 8.659771 \n",
      "index:2    MSE: 7.249311 \n",
      "index:3    MSE: 8.281296 \n",
      "index:4    MSE: 13.171264 \n",
      "index:5    MSE: 6.867240 \n",
      "index:6    MSE: 8.904328 \n",
      "index:7    MSE: 7.685376 \n",
      "index:8    MSE: 14.933533 \n",
      "index:9    MSE: 9.649515 \n",
      "index:10    MSE: 6.437246 \n",
      "index:11    MSE: 6.898342 \n",
      "index:12    MSE: 12.147911 \n",
      "index:13    MSE: 11.418834 \n",
      "index:14    MSE: 4.403970 \n",
      "index:15    MSE: 4.626034 \n",
      "index:16    MSE: 9.444518 \n",
      "index:17    MSE: 16.786934 \n",
      "Test: xuanxi  average MSE: 9.266873 average fix MSE: 9.444712  average amb MSE: 8.911192\n",
      "torch.Size([41, 300, 2]) torch.Size([41, 300]) torch.Size([41, 300, 2])\n",
      "index:0    MSE: 3.124770 \n",
      "index:1    MSE: 6.239569 \n",
      "index:2    MSE: 4.075070 \n",
      "index:3    MSE: 2.659395 \n",
      "index:4    MSE: 6.230811 \n",
      "index:5    MSE: 4.145534 \n",
      "index:6    MSE: 8.882356 \n",
      "index:7    MSE: 2.107532 \n",
      "index:8    MSE: 3.293491 \n",
      "index:9    MSE: 4.590911 \n",
      "index:10    MSE: 4.187813 \n",
      "index:11    MSE: 5.116708 \n",
      "index:12    MSE: 4.344312 \n",
      "index:13    MSE: 3.947367 \n",
      "index:14    MSE: 7.030051 \n",
      "index:15    MSE: 4.070197 \n",
      "index:16    MSE: 9.963728 \n",
      "index:17    MSE: 5.815287 \n",
      "index:18    MSE: 8.236509 \n",
      "index:19    MSE: 8.463483 \n",
      "index:20    MSE: 7.088200 \n",
      "index:21    MSE: 3.114412 \n",
      "index:22    MSE: 5.817140 \n",
      "index:23    MSE: 6.139960 \n",
      "index:24    MSE: 5.483325 \n",
      "index:25    MSE: 3.082476 \n",
      "index:26    MSE: 5.070166 \n",
      "index:27    MSE: 6.910384 \n",
      "index:28    MSE: 3.443744 \n",
      "index:29    MSE: 4.820220 \n",
      "index:30    MSE: 2.544681 \n",
      "index:31    MSE: 5.415138 \n",
      "index:32    MSE: 2.606009 \n",
      "index:33    MSE: 8.700025 \n",
      "index:34    MSE: 8.061444 \n",
      "index:35    MSE: 3.867870 \n",
      "index:36    MSE: 2.996156 \n",
      "index:37    MSE: 5.427848 \n",
      "index:38    MSE: 4.570652 \n",
      "index:39    MSE: 6.482585 \n",
      "index:40    MSE: 7.599502 \n",
      "Test: jian  average MSE: 5.262605 average fix MSE: 5.607352  average amb MSE: 4.665046\n",
      "torch.Size([18, 300, 2]) torch.Size([18, 300]) torch.Size([18, 300, 2])\n",
      "index:0    MSE: 2.274868 \n",
      "index:1    MSE: 4.523944 \n",
      "index:2    MSE: 4.470959 \n",
      "index:3    MSE: 4.048123 \n",
      "index:4    MSE: 4.117293 \n",
      "index:5    MSE: 3.746017 \n",
      "index:6    MSE: 4.895619 \n",
      "index:7    MSE: 4.665195 \n",
      "index:8    MSE: 3.143293 \n",
      "index:9    MSE: 5.041381 \n",
      "index:10    MSE: 2.876738 \n",
      "index:11    MSE: 1.986970 \n",
      "index:12    MSE: 3.482958 \n",
      "index:13    MSE: 5.145780 \n",
      "index:14    MSE: 5.632290 \n",
      "index:15    MSE: 4.991009 \n",
      "index:16    MSE: 4.909566 \n",
      "index:17    MSE: 2.447089 \n",
      "Test: ru  average MSE: 4.022172 average fix MSE: 4.101491  average amb MSE: 3.863534\n",
      "torch.Size([18, 300, 2]) torch.Size([18, 300]) torch.Size([18, 300, 2])\n",
      "index:0    MSE: 8.420018 \n",
      "index:1    MSE: 5.856242 \n",
      "index:2    MSE: 6.595676 \n",
      "index:3    MSE: 7.324004 \n",
      "index:4    MSE: 5.228624 \n",
      "index:5    MSE: 5.492759 \n",
      "index:6    MSE: 9.261571 \n",
      "index:7    MSE: 7.131416 \n",
      "index:8    MSE: 2.036144 \n",
      "index:9    MSE: 2.815003 \n",
      "index:10    MSE: 8.713049 \n",
      "index:11    MSE: 11.420476 \n",
      "index:12    MSE: 3.233323 \n",
      "index:13    MSE: 3.342614 \n",
      "index:14    MSE: 5.248461 \n",
      "index:15    MSE: 19.447155 \n",
      "index:16    MSE: 7.692953 \n",
      "index:17    MSE: 3.959701 \n",
      "Test: petrov  average MSE: 6.845510 average fix MSE: 7.025156  average amb MSE: 6.486221\n",
      "torch.Size([36, 300, 2]) torch.Size([36, 300]) torch.Size([36, 300, 2])\n",
      "index:0    MSE: 6.587643 \n",
      "index:1    MSE: 13.162009 \n",
      "index:2    MSE: 9.595383 \n",
      "index:3    MSE: 4.893064 \n",
      "index:4    MSE: 7.437333 \n",
      "index:5    MSE: 4.896658 \n",
      "index:6    MSE: 8.205438 \n",
      "index:7    MSE: 7.138879 \n",
      "index:8    MSE: 5.499982 \n",
      "index:9    MSE: 5.997474 \n",
      "index:10    MSE: 4.050234 \n",
      "index:11    MSE: 3.615386 \n",
      "index:12    MSE: 5.043388 \n",
      "index:13    MSE: 8.663309 \n",
      "index:14    MSE: 7.171034 \n",
      "index:15    MSE: 10.333711 \n",
      "index:16    MSE: 6.394071 \n",
      "index:17    MSE: 8.074868 \n",
      "index:18    MSE: 7.792476 \n",
      "index:19    MSE: 11.000921 \n",
      "index:20    MSE: 9.820883 \n",
      "index:21    MSE: 6.308651 \n",
      "index:22    MSE: 5.091035 \n",
      "index:23    MSE: 3.799814 \n",
      "index:24    MSE: 6.539535 \n",
      "index:25    MSE: 6.089266 \n",
      "index:26    MSE: 3.813229 \n",
      "index:27    MSE: 8.481205 \n",
      "index:28    MSE: 8.375554 \n",
      "index:29    MSE: 12.194140 \n",
      "index:30    MSE: 9.955812 \n",
      "index:31    MSE: 8.448032 \n",
      "index:32    MSE: 6.279804 \n",
      "index:33    MSE: 6.451901 \n",
      "index:34    MSE: 6.296378 \n",
      "index:35    MSE: 9.092880 \n",
      "Test: mayank  average MSE: 7.294205 average fix MSE: 7.200642  average amb MSE: 7.762015\n",
      "torch.Size([17, 300, 2]) torch.Size([17, 300]) torch.Size([17, 300, 2])\n",
      "index:0    MSE: 13.271237 \n",
      "index:1    MSE: 14.573249 \n",
      "index:2    MSE: 13.222757 \n",
      "index:3    MSE: 15.042178 \n",
      "index:4    MSE: 7.902582 \n",
      "index:5    MSE: 12.911277 \n",
      "index:6    MSE: 5.229241 \n",
      "index:7    MSE: 15.822227 \n",
      "index:8    MSE: 11.150130 \n",
      "index:9    MSE: 14.319805 \n",
      "index:10    MSE: 10.490977 \n",
      "index:11    MSE: 16.127228 \n",
      "index:12    MSE: 13.890433 \n",
      "index:13    MSE: 11.005697 \n",
      "index:14    MSE: 14.347310 \n",
      "index:15    MSE: 13.166468 \n",
      "index:16    MSE: 16.186312 \n",
      "Test: kun  average MSE: 12.862300 average fix MSE: 12.885077  average amb MSE: 12.820548\n",
      "torch.Size([18, 300, 2]) torch.Size([18, 300]) torch.Size([18, 300, 2])\n",
      "index:0    MSE: 6.880949 \n",
      "index:1    MSE: 4.840830 \n",
      "index:2    MSE: 5.375501 \n",
      "index:3    MSE: 3.714990 \n",
      "index:4    MSE: 5.726380 \n",
      "index:5    MSE: 4.461486 \n",
      "index:6    MSE: 11.250606 \n",
      "index:7    MSE: 9.014411 \n",
      "index:8    MSE: 2.779470 \n",
      "index:9    MSE: 4.513560 \n",
      "index:10    MSE: 7.654818 \n",
      "index:11    MSE: 9.592678 \n",
      "index:12    MSE: 4.584153 \n",
      "index:13    MSE: 3.022655 \n",
      "index:14    MSE: 5.650543 \n",
      "index:15    MSE: 9.288013 \n",
      "index:16    MSE: 4.725119 \n",
      "index:17    MSE: 6.542491 \n",
      "Test: ke  average MSE: 6.089925 average fix MSE: 6.551543  average amb MSE: 5.166690\n",
      "torch.Size([18, 300, 2]) torch.Size([18, 300]) torch.Size([18, 300, 2])\n",
      "index:0    MSE: 11.474059 \n",
      "index:1    MSE: 8.083942 \n",
      "index:2    MSE: 15.519814 \n",
      "index:3    MSE: 10.357048 \n",
      "index:4    MSE: 10.388592 \n",
      "index:5    MSE: 8.533571 \n",
      "index:6    MSE: 8.772466 \n",
      "index:7    MSE: 8.832397 \n",
      "index:8    MSE: 9.528954 \n",
      "index:9    MSE: 11.353944 \n",
      "index:10    MSE: 13.940977 \n",
      "index:11    MSE: 7.369286 \n",
      "index:12    MSE: 11.349254 \n",
      "index:13    MSE: 12.399935 \n",
      "index:14    MSE: 7.542022 \n",
      "index:15    MSE: 10.395318 \n",
      "index:16    MSE: 9.626837 \n",
      "index:17    MSE: 11.898370 \n",
      "Test: jieyun  average MSE: 10.409266 average fix MSE: 10.250813  average amb MSE: 10.726171\n",
      "torch.Size([18, 300, 2]) torch.Size([18, 300]) torch.Size([18, 300, 2])\n",
      "index:0    MSE: 10.886104 \n",
      "index:1    MSE: 8.317687 \n",
      "index:2    MSE: 3.651636 \n",
      "index:3    MSE: 4.872100 \n",
      "index:4    MSE: 6.606669 \n",
      "index:5    MSE: 10.840297 \n",
      "index:6    MSE: 13.206149 \n",
      "index:7    MSE: 12.684476 \n",
      "index:8    MSE: 5.550243 \n",
      "index:9    MSE: 4.491174 \n",
      "index:10    MSE: 12.239049 \n",
      "index:11    MSE: 5.019694 \n",
      "index:12    MSE: 7.028700 \n",
      "index:13    MSE: 7.773203 \n",
      "index:14    MSE: 11.372644 \n",
      "index:15    MSE: 7.052104 \n",
      "index:16    MSE: 5.822924 \n",
      "index:17    MSE: 9.426714 \n",
      "Test: haoyang  average MSE: 8.157865 average fix MSE: 8.472256  average amb MSE: 7.529083\n",
      "torch.Size([18, 300, 2]) torch.Size([18, 300]) torch.Size([18, 300, 2])\n",
      "index:0    MSE: 14.257738 \n",
      "index:1    MSE: 13.520842 \n",
      "index:2    MSE: 10.994637 \n",
      "index:3    MSE: 15.162542 \n",
      "index:4    MSE: 13.995238 \n",
      "index:5    MSE: 14.458153 \n",
      "index:6    MSE: 9.718411 \n",
      "index:7    MSE: 10.118525 \n",
      "index:8    MSE: 12.028096 \n",
      "index:9    MSE: 14.784842 \n",
      "index:10    MSE: 10.078894 \n",
      "index:11    MSE: 8.667986 \n",
      "index:12    MSE: 16.643278 \n",
      "index:13    MSE: 12.813953 \n",
      "index:14    MSE: 6.817058 \n",
      "index:15    MSE: 9.970555 \n",
      "index:16    MSE: 14.977865 \n",
      "index:17    MSE: 16.246660 \n",
      "Test: ish  average MSE: 12.514181 average fix MSE: 11.905512  average amb MSE: 13.731525\n",
      "torch.Size([18, 300, 2]) torch.Size([18, 300]) torch.Size([18, 300, 2])\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "index:0    MSE: 2.083045 \n",
      "index:1    MSE: 0.850974 \n",
      "index:2    MSE: 2.506006 \n",
      "index:3    MSE: 4.720536 \n",
      "index:4    MSE: 2.377388 \n",
      "index:5    MSE: 1.390704 \n",
      "index:6    MSE: 5.001315 \n",
      "index:7    MSE: 5.227843 \n",
      "index:8    MSE: 3.624907 \n",
      "index:9    MSE: 3.388038 \n",
      "index:10    MSE: 4.121620 \n",
      "index:11    MSE: 3.382268 \n",
      "index:12    MSE: 4.878640 \n",
      "index:13    MSE: 3.862948 \n",
      "index:14    MSE: 4.217146 \n",
      "index:15    MSE: 4.278006 \n",
      "index:16    MSE: 2.603887 \n",
      "index:17    MSE: 6.338726 \n",
      "Test: chen  average MSE: 3.603000 average fix MSE: 4.243779  average amb MSE: 2.321442\n",
      "torch.Size([18, 300, 2]) torch.Size([18, 300]) torch.Size([18, 300, 2])\n",
      "index:0    MSE: 9.921135 \n",
      "index:1    MSE: 10.272963 \n",
      "index:2    MSE: 8.231771 \n",
      "index:3    MSE: 12.503972 \n",
      "index:4    MSE: 10.258164 \n",
      "index:5    MSE: 13.713510 \n",
      "index:6    MSE: 12.947553 \n",
      "index:7    MSE: 4.383501 \n",
      "index:8    MSE: 17.767998 \n",
      "index:9    MSE: 18.261978 \n",
      "index:10    MSE: 6.165503 \n",
      "index:11    MSE: 2.912947 \n",
      "index:12    MSE: 12.669505 \n",
      "index:13    MSE: 17.087898 \n",
      "index:14    MSE: 2.780063 \n",
      "index:15    MSE: 3.300200 \n",
      "index:16    MSE: 19.509226 \n",
      "index:17    MSE: 14.052616 \n",
      "Test: tabish  average MSE: 10.930028 average fix MSE: 10.986583  average amb MSE: 10.816919\n",
      "torch.Size([17, 300, 2]) torch.Size([17, 300]) torch.Size([17, 300, 2])\n",
      "index:0    MSE: 31.158581 \n",
      "index:1    MSE: 25.376184 \n",
      "index:2    MSE: 28.300026 \n",
      "index:3    MSE: 31.428986 \n",
      "index:4    MSE: 30.348288 \n",
      "index:5    MSE: 28.408979 \n",
      "index:6    MSE: 21.229340 \n",
      "index:7    MSE: 20.564230 \n",
      "index:8    MSE: 27.011927 \n",
      "index:9    MSE: 28.171764 \n",
      "index:10    MSE: 25.375887 \n",
      "index:11    MSE: 21.222729 \n",
      "index:12    MSE: 26.355713 \n",
      "index:13    MSE: 28.550306 \n",
      "index:14    MSE: 24.612728 \n",
      "index:15    MSE: 23.111156 \n",
      "index:16    MSE: 30.650261 \n",
      "Test: john  average MSE: 26.581003 average fix MSE: 25.168732  average amb MSE: 29.170174\n",
      "average: 9.133794\n",
      "average fix: 9.179363\n",
      "average amb: 9.052732\n",
      "[4.034186840057373, 9.266873359680176, 5.2626051902771, 4.022172451019287, 6.845510482788086, 7.2942047119140625, 12.862299919128418, 6.089925289154053, 10.409266471862793, 8.157864570617676, 12.514181137084961, 3.6029999256134033, 10.930027961730957, 26.581003189086914]\n",
      "[4.667441368103027, 9.444711685180664, 5.607351779937744, 4.1014909744262695, 7.025156021118164, 7.200642108917236, 12.885076522827148, 6.551543235778809, 10.250812530517578, 8.47225570678711, 11.905511856079102, 4.243779182434082, 10.98658275604248, 25.168731689453125]\n",
      "[2.7676806449890137, 8.911191940307617, 4.665046215057373, 3.863534450531006, 6.486220836639404, 7.762015342712402, 12.820548057556152, 5.166689872741699, 10.726171493530273, 7.529082775115967, 13.731525421142578, 2.321442127227783, 10.816919326782227, 29.17017364501953]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py36] *",
   "language": "python",
   "name": "conda-env-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}