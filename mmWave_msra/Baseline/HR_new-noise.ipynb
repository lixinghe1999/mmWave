{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import os\r\n",
    "import pickle\r\n",
    "import numpy as np\r\n",
    "import matplotlib as mpl\r\n",
    "\r\n",
    "from easydict import EasyDict\r\n",
    "import pandas as pd\r\n",
    "import torch\r\n",
    "import torch.nn as nn\r\n",
    "import torch.optim as optim\r\n",
    "import torch.nn.functional as F\r\n",
    "from torch.autograd import Variable\r\n",
    "import torch.utils.data as Data\r\n",
    "from scipy.io import loadmat\r\n",
    "import scipy.io as sio"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# parameter\r\n",
    "batch_size = 8\r\n",
    "opts = EasyDict()\r\n",
    "opts.input_size = 2\r\n",
    "opts.output_size = 1\r\n",
    "opts.hidden_size = 128\r\n",
    "opts.num_layers = 2\r\n",
    "opts.nums_epoch = 100\r\n",
    "opts.dropout = 0.5 \r\n",
    "opts.isBidirectional = True;\r\n",
    "opts.layer_size = 2\r\n",
    "opts.sequence_length = 300\r\n",
    "opts.attention_size = 10\r\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\r\n",
    "\r\n",
    "name_labels = [\"noise\"]\r\n",
    "# ,\"noise\",\"differentplace\"  \"tabish\" \"john\"\r\n",
    "def ZscoreNormalization(x):\r\n",
    "    \"\"\"Z-score normaliaztion\"\"\"\r\n",
    "    std = np.std(x)\r\n",
    "    mean = np.mean(x)\r\n",
    "    x = (x - np.mean(x)) / np.std(x)\r\n",
    "    return x,mean,std\r\n",
    "file_power_name = []\r\n",
    "file_HR_name = []\r\n",
    "for i in range(1,11):\r\n",
    "    name = 'radar_'+ str(i).rjust(2,'0') + '.csv'\r\n",
    "    file_power_name.append(name)\r\n",
    "print(file_power_name)\r\n",
    "for i in range(1,11):\r\n",
    "    name = 'HR'+ str(i).rjust(2,'0') + '.npy'\r\n",
    "    file_HR_name.append(name)   \r\n",
    "print(file_HR_name)\r\n",
    "\r\n",
    "para_normal_sep = 6\r\n",
    "para_normal_jian = 15"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# LSTM model\r\n",
    "class LSTM(nn.Module):\r\n",
    "    def __init__(self):\r\n",
    "        super(LSTM, self).__init__()\r\n",
    "        self.lstm = torch.nn.LSTM(input_size = opts.input_size,hidden_size = opts.hidden_size, num_layers = opts.num_layers,\r\n",
    "                                  batch_first = True,bidirectional = opts.isBidirectional,dropout = opts.dropout)\r\n",
    "        for name, param in self.lstm.named_parameters():\r\n",
    "#             if 'bias' in name:\r\n",
    "#                 nn.init.constant_(param, 0.0)\r\n",
    "            if 'weight' in name:\r\n",
    "                nn.init.xavier_uniform_(param)\r\n",
    "        self.out = torch.nn.Linear(opts.hidden_size*2, opts.output_size)\r\n",
    "    \r\n",
    "    def forward(self, sequence):\r\n",
    "        r_out,_ = self.lstm(sequence)\r\n",
    "        out = self.out(r_out)\r\n",
    "        return out\r\n",
    "# read power file\r\n",
    "def readPowerDir(dirPath,pathArray,res):\r\n",
    "    if dirPath[-1] == '/':\r\n",
    "        return\r\n",
    "    flag = False\r\n",
    "    allFiles = []\r\n",
    "    if os.path.isdir(dirPath):\r\n",
    "        fileList = os.listdir(dirPath)\r\n",
    "        fileList.sort()\r\n",
    "        for f in fileList:\r\n",
    "            if f in file_power_name:\r\n",
    "                flag = True\r\n",
    "            f = dirPath+'/'+f\r\n",
    "            if os.path.isdir(f):\r\n",
    "                subFiles = readPowerDir(f,pathArray,res)\r\n",
    "                allFiles = subFiles + allFiles \r\n",
    "            else:\r\n",
    "                if flag:\r\n",
    "                    \r\n",
    "                    pathArray.append(f)\r\n",
    "                    csv_data = pd.read_csv(f,engine='python',header=None)\r\n",
    "                    data = np.array(csv_data)\r\n",
    "                    for i in range(data.shape[0]):\r\n",
    "                        data[:,1],_,_ = ZscoreNormalization(data[:,1])\r\n",
    "                        data[:,2],_,_ = ZscoreNormalization(data[:,2])\r\n",
    "                    res.append(data)\r\n",
    "                    allFiles.append(f)\r\n",
    "                    flag = False\r\n",
    "    return allFiles\r\n",
    "\r\n",
    "# read HR file\r\n",
    "def readHRDir(dirPath,pathArray,res):\r\n",
    "    if dirPath[-1] == '/':\r\n",
    "        return\r\n",
    "    flag = False\r\n",
    "    allFiles = []\r\n",
    "    if os.path.isdir(dirPath):\r\n",
    "        fileList = os.listdir(dirPath)\r\n",
    "        fileList.sort()\r\n",
    "        for f in fileList:\r\n",
    "            if f in file_HR_name:\r\n",
    "                flag = True\r\n",
    "            f = dirPath+'/'+f\r\n",
    "            if os.path.isdir(f):\r\n",
    "                subFiles = readHRDir(f,pathArray,res)\r\n",
    "                allFiles = subFiles + allFiles \r\n",
    "            else:\r\n",
    "                if flag:\r\n",
    "                    \r\n",
    "                    pathArray.append(f)\r\n",
    "                    data = np.load(f)\r\n",
    "#                     for i in range(data.shape[0]):\r\n",
    "#                         data[:,1],_,_ = ZscoreNormalization(data[:,1])\r\n",
    "#                         data[:,0],_,_ = ZscoreNormalization(data[:,0])\r\n",
    "                    res.append(data)\r\n",
    "                    allFiles.append(f)\r\n",
    "                    flag = False\r\n",
    "    return allFiles\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "average = []\r\n",
    "average_fix = []\r\n",
    "average_amb = []\r\n",
    "# Cross-validation len(name_labels)\r\n",
    "for i in range(len(name_labels)-1):\r\n",
    "    name_mask = []\r\n",
    "    name_mask.append(name_labels[i])\r\n",
    "    # read power and distance from file according ro name_labels as trainset\r\n",
    "    PowerTrain = np.array([0])\r\n",
    "    HRTrain = np.array([0])\r\n",
    "    for name in name_labels:\r\n",
    "        if(name in name_mask):\r\n",
    "            continue\r\n",
    "        pathArray =  []\r\n",
    "        power = []\r\n",
    "        HR = []\r\n",
    "        path = \"/.../.../RobustVSDataset/\"+name\r\n",
    "        res = readPowerDir(path,pathArray,power)\r\n",
    "        pathArray =  []\r\n",
    "        res = readHRDir(path,pathArray,HR)\r\n",
    "        power = np.array(power)\r\n",
    "        HR = np.array(HR)\r\n",
    "        PowerTrain = power if  PowerTrain.any() == 0 else np.concatenate((PowerTrain, power), axis = 0)\r\n",
    "        HRTrain = HR if  HRTrain.any() == 0 else np.concatenate((HRTrain, HR), axis = 0)\r\n",
    "    # read power and distance from file according ro name_mask as testset\r\n",
    "    PowerTest = np.array([0])\r\n",
    "    HRTest = np.array([0])    \r\n",
    "    for name in name_mask:\r\n",
    "        pathArray =  []\r\n",
    "        power = []\r\n",
    "        HR = []\r\n",
    "        path = \"/.../.../RobustVSDataset/\"+ name\r\n",
    "        res = readPowerDir(path,pathArray,power)\r\n",
    "        pathArray =  []\r\n",
    "        res = readHRDir(path,pathArray,HR)\r\n",
    "        power = np.array(power)\r\n",
    "        HR = np.array(HR)\r\n",
    "        PowerTest = power if  PowerTest.any() == 0 else np.concatenate((PowerTest, power), axis = 0)\r\n",
    "        HRTest = HR if  HRTest.any() == 0 else np.concatenate((HRTest, HR), axis = 0)\r\n",
    "#     print(\"Read file success!\")\r\n",
    "    \r\n",
    "    \r\n",
    "    model = LSTM()\r\n",
    "    model.to(device)\r\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.005)   # optimize parameters\r\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.8,weight_decay=1e-4)\r\n",
    "    loss_func = nn.MSELoss()\r\n",
    "\r\n",
    "    inputs, targets = torch.from_numpy(PowerTrain[:,:,1:]).type(torch.FloatTensor),torch.from_numpy(HRTrain[:,:,0]).type(torch.FloatTensor)\r\n",
    "    inputs, targets = inputs.to(device), targets.to(device)\r\n",
    "    torch_dataset = Data.TensorDataset(inputs,targets)\r\n",
    "    loader = Data.DataLoader(\r\n",
    "                    dataset=torch_dataset,      # torch TensorDataset format\r\n",
    "                    batch_size=batch_size,      # mini batch size\r\n",
    "                    shuffle=True,                            \r\n",
    "                )\r\n",
    "    train_loss, train_count, val_loss, val_count = 0,0,0,0\r\n",
    "    val_inputs,val_targets  = torch.from_numpy(PowerTest[:,:,1:]).type(torch.FloatTensor),torch.from_numpy(HRTest[:,:,0]).type(torch.FloatTensor)\r\n",
    "    val_inputs,val_targets = val_inputs.to(device), val_targets.to(device)\r\n",
    "    val_inputs = val_inputs.permute(1, 0, 2)\r\n",
    "    val_targets = val_targets.t()\r\n",
    "    val_targets = val_targets[:,:,np.newaxis]\r\n",
    "#   begin train\r\n",
    "    for epoch in range(0, opts.nums_epoch+1):\r\n",
    "        for step, (x, y) in enumerate(loader):\r\n",
    "            model.zero_grad()\r\n",
    "            model.train()\r\n",
    "            x = x.permute(1, 0, 2)\r\n",
    "            y = y.t()\r\n",
    "            y = y[:,:,np.newaxis]\r\n",
    "            prediction= model(x)\r\n",
    "            loss = loss_func(prediction, y)\r\n",
    "            optimizer.zero_grad()\r\n",
    "            loss.backward()\r\n",
    "            optimizer.step() \r\n",
    "            train_loss += loss.item()\r\n",
    "            train_count += 1\r\n",
    "\r\n",
    "        model.eval()\r\n",
    "        with torch.no_grad():\r\n",
    "            val_predict = model(val_inputs)\r\n",
    "            loss_ = loss_func(val_predict, val_targets)\r\n",
    "            val_loss += loss_.item()\r\n",
    "            val_count += 1\r\n",
    "        if(epoch% 50 == 0):\r\n",
    "            print('Epoch %d / %d     Train loss: %f     val loss: %f'% (epoch,opts.nums_epoch,  train_loss/train_count,val_loss/val_count)) \r\n",
    "    val_predict = model(val_inputs)\r\n",
    "    sum = 0\r\n",
    "    sum_fix = 0\r\n",
    "    sum_amb = 0\r\n",
    "    for i in range(val_predict.shape[1]):\r\n",
    "        if name_mask[0] == \"jian\":\r\n",
    "            para = para_normal_jian\r\n",
    "        else:\r\n",
    "            para = para_normal_sep\r\n",
    "        if(i < para):\r\n",
    "            sum_amb += torch.sum(torch.abs(val_predict[:,i]-val_targets[:,i]))/300\r\n",
    "        else:\r\n",
    "            sum_fix += torch.sum(torch.abs(val_predict[:,i]-val_targets[:,i]))/300\r\n",
    "        sum += torch.sum(torch.abs(val_predict[:,i]-val_targets[:,i]))/300\r\n",
    "        print('index:%d    MSE: %f '%(i,torch.sum(torch.abs(val_predict[:,i]-val_targets[:,i]))/300))\r\n",
    "        average.append(torch.sum(torch.abs(val_predict[:,i]-val_targets[:,i])).item()/300)\r\n",
    "    print('Test: %s  average MSE: %f' % (name_mask[0],sum/val_predict.shape[1] ))\r\n",
    "                                                                            \r\n",
    "   \r\n",
    "    \r\n",
    "# print(\"average: %f\" %(np.mean(average)))\r\n",
    "# print(\"average fix: %f\" %(np.mean(average_fix)))\r\n",
    "# print(\"average amb: %f\" %(np.mean(average_amb)))\r\n",
    "print(average)\r\n",
    "\r\n",
    "np.savetxt(\"generation_HR_noise.csv\", average)\r\n",
    "print(average_fix)\r\n",
    "print(average_amb)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py36] *",
   "language": "python",
   "name": "conda-env-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}